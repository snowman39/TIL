### 210311

#### 오늘의 개념

* 스트라이드 : 합성곱의 파라미터로, 두 번의 연속적인 윈도우 사이의 거리를 의미한다
  * 특성 맵을 다운샘플링할 때 사용할 수 있다 
  * 스트라이드 합성곱은 실전에서 드물게 사용되나 특정 모델에서는 유용하게 사용될 수 있다

* 최대 풀링 : 특성 맵에서 윈도우에 맞는 패치를 추출하고 각 채널별로 최대값을 출력한다
  * 합성곱과 개념적으로 비슷하나, 추출한 패치에 학습된 선형 변환을 적용하는 대신 하드코딩된 최댓값 추출 연산을 사용한다
  * 합성곱과 가장 큰 차이점은 최대 풀링은 보통 2 * 2 윈도우위 스트라이드 2 를 사용하여 특성 맵을 절반으로 다운샘플링하지만 합성곱은 3 * 3 윈도우와 스트라이드 1을 사용한다

* 평균 폴링 : 입력 패치의 채널별 평균값을 계산하여 변환하는 방법

#### 오늘의 예제

완전 연결층으로 MNIST 숫자 이미지 학습

```python

from keras.datasets import mnist
from keras.utils import to_categorical
from keras import layers
from keras import models

model = models.Sequential()
model.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))
model.add(layers.Dense(10, activation='softmax'))

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype('float32') / 255

test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype('float32') / 255

train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

model.fit(train_images, train_labels, epochs=5, batch_size=128)
test_loss, test_acc = model.evaluate(test_images, test_labels)
test_acc

```
시행 결과 : 97.85 % 의 테스트 정확도 도달

합성곱 층으로 MNIST 숫자 이미지 학습

```python
from keras.datasets import mnist
from keras.utils import to_categorical
from keras import layers
from keras import models

model = models.Sequential()
model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3), activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 28, 28, 1))
train_images = train_images.astype('float32') / 255

test_images = test_images.reshape((10000, 28, 28, 1))
test_images = test_images.astype('float32') / 255

train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=5, batch_size=64)

test_loss, test_acc = model.evaluate(test_images, test_labels)
test_acc

```
시행 결과 : 99.2 % 의 테스트 정확도 도달

관찰한 점 
* 구글 Colab 환경 상에서 학습을 시킬 때 완전 연결 층으로 학습시킬 때 보다, 컨브넷으로 학습시킬 때 시간이 더 오래걸람 ( 1 epochs 당 평균 4s / 46s )
* 컨브넷이 이미지 패턴 학습에 더 높은 효율성을 보였다

#### 오늘의 배운 내용

* 완전 연결층과 합성곱 층 사이의 근본적인 차이는, Dense 층은 입력 특성 공간에 있는 전역 패턴을 학습하지만, 합성곱 층은 지역 패턴을 합성한다는 점이다
* 완전 연결 네트워크의 경우 새로운 위치에서 나타난 것은 새로운 패턴으로 학습하는 반면, 컨브넷을 통해 학습된 지역 패턴은 다른 곳에서도 적용을 할 수 있다 (평행 이동 불변성)
* 이러한 성질은 컨브넷이 이미지를 효율적으로 처리하게 만들어준다 (적은 수의 훈련 샘플을 이용해 일반화 능력을 가진 표현 학습 가능하기 때문)
* 컨브넷은 공간적 계층 구조를 학습할 수 있다 (근본적으로 우리가 보는 세상은 공간적 계층 구조를 가진다)
* 합성곱은 핵심적인 2개의 파라미터로 정의된다
  * 입력으로부터 뽑아낼 패치의 크기 (전형적으로 3*3 또는 5*5 를 사용)
  * 특성 맵의 출력 깊이 (합성곱으로 계산할 필터의 수) 
* 합성곱의 출력 높이와 너비는 입력의 높이와 너비와 다를 수 있는데, 이는 경계 문제, 입력 특성 맵에 패딩을 추가하여 대응할 수 있거나, 스트라이드 사용 여부에 따라 달라진다
* 다운 샘플링을 사용하는 이유는 처리할 특성 맵의 가중치 개수를 줄이기 위해서이다
  * 연속적인 합성곱 층이 점점 커진 윈도우를 통해 바라보도록 만들어 필터의 공간적 계층 구조를 구성한다
