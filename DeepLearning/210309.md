### 210309


#### 오늘의 개념

* 지도 학습 : 훈련 데이터의 입력과 타깃 사이의 관계를 학습하는 것
  * 가장 흔한 경우로 대부분 분류와 회귀로 구성되지만, 시퀀스 생성, 물체 감지 등의 예외가 존재
  * 예시 : 음성 인식, 이미지 분류

* 비지도 학습 : 어떤 타깃도 사용하지 않고 입력 데이터에 대한 흥미로운 변환을 찾는 방법
  * 데이터 시각화, 압축, 노이즈 제거 또는 데이터 간의 상관관계를 더 잘 이해하기 위해 사용
  * 종종 지도 학습 전에 데이터셋을 더 잘 이해하기 위해 필수적으로 거침
  * 예시 : 차원 축소, 군집


* 자기 지도 학습: 지도 학습이지만, 사람이 만든 레이블을 사용하지 않는 방식
  * 학습과정에 사람이 개입하지 않는 지도 학습
  * 레이블이 필요하긴 하지만, 보통 경험적 알고리즘을 사용해서 입력 데이터로부터 생성
  * 예시 : 오토 인코더

* 강화 학습 : 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 에이전트를 학습시키는 방식
  * 아직 대부분은 게임에서 적용됨 

* 하이퍼파라미터 : 모델의 층의 수나 층의 유닛 개수

* 정보 누설 : 검증 세트의 모델 성능에 기반해 모델의 하이퍼파라미터를 조정할 떄마다 검증 데이터에 관한 정보가 모델로 새는 현상

* 단순 홀드아웃 검증 : 데이터 일정량을 테스트 세트로 떼어놓고 남은 데이터로 훈련하는 방식
 * 데이터가 적을 때는 검증 세트와 테스트 세트의 샘블이 너무 적어서 주어진 전체 데이터를 통계적으로 대표하지 못할 수 있다.

* 반복 K-겹 교차 검증 : 비교적 가용 데이터가 적은 경우 사용
 * K-겹 교차 검증을 여러 번 적용하되 K 개의 분할로 나누기 전에 매번 데이터를 무작위로 섞는다
 * 최종 점수는 모든 K-겹 교차 검증을 실행해서 얻은 점수의 평균
 * 결국 n * K 의 모델을 훈련하고 평가해야 해서 비용이 많이 든다

* 데이터 벡터화 : 처리해야 할 데이터를 텐서로 변환하는 과정

* 특성 공학 : 데이터와 머신 러닝 알고리즘에 관한 지식을 사용하는 단계

* 과소 적합 : 훈련 데이터의 손실이 낮아질수록 테스트 데이터의 손실이 낮아지는 경우
 * 모델 성능이 계속 발전될 여지가 있는 상황, 훈련 데이터의 관련 특성을 모두 학습하진 못한 상황

#### 오늘의 배운점

* 머신 러닝 모델 평가의 핵심은 가용한 데이터를 훈련 / 검증 /  테스트 3개의 세트로 나누는 것이다.
 * 훈련, 테스트 2개로만 나누지 않는 이유는 항상 모델의 설정을 튜닝하기 때문이다 (예 : 층의 수나 층의 유닛 수)
 * 여러 번 모델을 수정하게 되면, 검증 세트에 관한 정보가 많이 누설되기 때문에 새로운 데이터셋이 꼭 필요하다

* 평가 방식을 선택할 때 유념해야 할 3가지
 * 대표성 있는 데이터 : 훈련 세트와 테스트 세트가 주어진 데이터에 대한 대표성이 있어야 한다 (자주 사용되는 방식: 셔플링)
 * 시간의 방향 : 과거로부터 미래를 예측하려 할 때는 데이터 분할 전에 무작위로 섞어서는 절대 안된다 ( 미래의 정보가 누설되기 때문 )
  * 테스트 세트는 무조건 훈련 세트보다 미래의 데이터여야 한다
 * 데이터 중복 : 데이터 포인트가 두 번 등장하면 훈련 세트와 검증 세트에서도 중복될 수 있다
  * 훈련 데이터의 일부로 테스트 하게 되는 최악의 경우 발생 가능

* 네트워크를 쉽게 학습시키기 위한 특징
 * 작은 값을 취한다 (일반적으로 대부분의 값이 0 ~ 1 사이)
 * 균일해야 한다 (모든 특성이 대체로 비슷한 범위를 가진다)

* 누락된 값을 다루는 경우
 * 신경망에서 0이 사전에 정의된 의미 있는 값이 아니라면 누락된 값을 0으로 입력 (0이 누락된 데이터임을 학습할 것)
 * 네트워크가 누락된 값이 없는 데이터에서 훈련되었을 경우, 누락된 값을 무시하는 법을 알지 못하므로 누락된 값이 있는 훈련 샘플을 고의적으로 만들어야 함
  * 훈련 샘플 일부를 여러벌 복사해서 빠질 것 같은 특성을 제거

* 심층 신경망에도 특성 공학을 신경써야 하는 이유
 * 좋은 특성은 적은 자원을 사용해서 문제를 멋지게 풀어낼 수 있음
 * 더 적은 데이터로 문제를 풀 수 있음, 샘플이 적은 경우 특성의 정보가 중요해짐

* 머신 러닝의 근본적인 이슈는 최적화와 일반화 사이의 줄다리기이다
