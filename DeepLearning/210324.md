### 210324

케라스 창시자에게 배우는 딥러닝 책은 완독 했기 때문에, 오늘부터는 SNUON의 IoT·인공지능·빅데이터 개론 및 실습 강의와, 수강중인 강의에서 배우는 내용을 요약해서 업로드한다

#### 오늘의 개념

* Bayes optimal classifier : True function p(x | y) 를 알거나 sample 숫자가 infinite 한 경우 추정치를 예측하는 방법
  * 가장 좋은 퍼포먼스를 나타낼 수 있지만, 현실에서는 불가능하다
  * 이 방법이 맞지 않는 경우, 노이즈가 너무 큰 경우로 예측이 불가능하다고 판단할 수 있다

* KNN(k-nearest neighbors) 알고리즘: 패턴 인식에서, 분류나 회귀에 사용되는 비모수 방식으로, 입력이 특징 공간 내 k개의 가장 가까운 훈련 데이터로 구성되고, 출력은 k-NN이 분류로 사용되었는지 또는 회귀로 사용되었는지에 따라 다르다
  * k 값이 작을 수록 variance 가 높아지고, k 값이 커질 수록 bias 가 높아진다

* correlation : 두 무작위 변수 또는 이변 량 데이터 간의 인과관계에 상관 없이 통계적 상관 관계를 의미한다

* causality : 두 무작위 변수 또는 이변 량 데이터 간의 인과 관계를 의미한다
  * 일반적으로 데이터 자체는 인과관계를 나타낼 수 없다
  * 다만, Time sequence data나 두 데이터의 상관관계가 delay가 있을 경우 인과 관계를 유추할 수 있다

#### 오늘의 배운점

* regression 과 classification 이 나타내는 오류의 경향성이 다른 이유는, 둘 다 확률을 추정하지만 classification의 경우 그 확률의 근접성이 아닌 옳은 클래스가 조금이라도 더 확률이 높게 나오면 맞는 예측이 되기 때문에 비교적 차이가 덜 드러난다
  * 예: 0 또는 1로 분류하는 문제를 풀기 위해서, 해당 샘플의 p(y=1) 을 계산한다. 이 때 확률값이 0.50001 이라도 1을 골라서 맞췄다면 error가 0이 된다
 
