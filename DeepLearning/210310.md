### 210310

#### 오늘의 개념

* 가중치 규제 : 과대적합을 완화하기 위해 네트워크의 복잡도에 제한을 두어 가중치가 작은 값을 갖도록 강제하는 것
* L1 규제 : 가중치의 절댓값에 비례하는 비용이 추가된다
* L2 규제 : 가중치의 제곱에 비례하는 비용이 추가 된다, 가중치 감쇠라고도 부른다
* 드롭아웃 : 훈련하는 동안 무작위로 층의 일부 출력 특성을 제외시키고, 테스트 단계에서는 층의 출력을 드롭아웃 비율에 비례해서 줄여주는 방법

* 컨브넷 : 합성곱 신경망이라고도 부른다, 주로 컴퓨터 비전 애플리케이션에 사용된다

#### 오늘의 배운점

* 과대적합을 막는 가장 단순한 방법은 모델의 크기(학습 파라미터의 수)를 줄이는 것이다
* 딥러닝에서 모델에 있는 학습파라미터 수를 모델의 용량이라고 말한다
* 적절한 모델 크기를 찾는 일반적인 작업 흐름은 비교적 적은 수의 층과 파라미터로 시작한다
* 네트워크의 크기가 클 수록 상대적으로 적은 에포크 수부터 과대적합이 시작되어 갈수록 더 심해진다
* 드롭아웃 방법의 핵심적인 아이디어는, 층의 출력 값에 노이즈를 추가하여 중요하지 않은 우연한 패턴을 깨뜨리는 것
* 주어진 문제의 성공 지표를 직접 최적화하는 것은 항상 가능하지는 않다
  * 때로는 지표를 손실 함수로 바꿀 수 있는 방법이 없다
  * 손실함수는 주어진 미니 배치 데이터에서 계산 가능하고, 미분 가능해야 한다
  * 예 : ROC AUC
