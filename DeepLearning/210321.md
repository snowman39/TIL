### 210321

#### 오늘의 개념

* 언어 모델 : 이전 토큰들이 주어졌을 때 다음 토큰의 확률을 모델링할 수 있는 네트워크로 언어의 통계적 구조인 잠재 공간을 탐색한다
  * 이를 훈련하고 나면 샘플링을 할 수 있다(새로운 시퀀스를 생성한다)
  * 초기 텍스트 문자열(조건 데이터)을 주입하고 새로운 글자나 단어를 생성할 수 있다 

* 탐욕적 샘플링 : 텍스트를 생성할 때, 항상 가장 높은 확률을 가진 글자를 선택하는 방법
  * 단순한 방법으로, 반복적이고 예상 가능한 문자열을 만들기 때문에 논리적인 언어처럼 보이지 않다

* 확률적 샘플링 : 다음 글자가 나올 확률이 있을 때, 그 글자를 확률적으로 선택하는 방법
  * 즉, 'e' 가 다음 글자가 될 확률이 0.3, 'd'가 다음 글자가 될 확률이 0.4 여도, 30% 확률로 e가 올 수 있다
  * 실제 같은 새로운 단어를 만들거나 재미있고 창의적인 문장을 생성하지만, 샘플링 과정에서 무작위성의 양을 조절할 방법이 없다

* 소프트맥스 온도 : 샘플링 과정에서 확률의 양을 조절하기 위해 사용하는 파라미터로, 샘플링에 사용되는 확률 분포의 엔트로피를 나타낸다

* 딥드림 : 합성곱 신경망이 학습한 표현을 사용해 예술적으로 이미지를 조작하는 기법
  * 특정 필터가 아닌 전체 층의 활성화를 최대화한다, 한꺼번에 많은 특성을 섞어 시각화한다
  * 입력 이미지는 시각 품질을 높이기 위해 여러 다른 스케일로 처리한다

* 뉴럴 스타일 트랜스퍼 : 질감, 색깔, 이미지에 있는 다양한 크기의 시각요소를 학습하여 이미지를 변경시키는 방법
  * 딥드림 이외에 딥러닝을 이용해 이미지를 변경하는 다른 분야
  * 변위 손실 : 생성된 이미지의 픽셀을 사용하여 계산하는 것으로, 생성된 이미지가 공간적인 연속성을 가지도록 도와주며 픽셀의 격자 무늬가 과도하게 나타나는 것을 막아준다
  * 느리지만 간단한 변환을 수행하기 떄문에 작고 빠른 컨브넷을 사용하여 학습할 수 있다

* 변이형 오토 인코더(VAE) : 입력을 저차원 잠재 공간으로 인코딩한 후 디코딩하여 복원하는 네트워크로, 딥러닝과 베이즈 추론의 아이디어를 혼합한 오토인코더이다
  * 재구성 손실(디코딩된 샘플이 원본 입력과 동일하도록 만든다)과 규제 손실( 잠재 공간을 잘 형성하고 훈련데이터의 과대적합을 줄이는) 2개의 손실 함수로 훈련한다

* 적대적 생성 신경망(GAN) : 생성된 이미지가 실제 이미지와 통계적으로 거의 구분되지 않도록 강제하여 실제 같은 합성 이미지를 생성하는 방법
  * 생성자 네트워크 : 램덤 벡터를 입력으로 받아 이를 합성된 이미지로 디코딩한다
  * 판별자 네트워크 : 이미지를 입력으로 받아 훈련 세트에서 온 이미지인지, 생성자 네트워크가 만든 이미지인지 판별한다 

#### 오늘의 배운점

* 텍스트를 샘플링 할 때, 무작위성이 너무 큰 경우(예 : 균등 확률 분포), 혹은 무작위성이 너무 작은 경우(예 : 탐욕적 샘플링) 흥미로운 결과를 만들기 어렵다

* 흥미는 주관적인 것이므로 최적의 엔트로피 값은 미리 알 수 없기에 여러 시도를 통해 사람이 판단해야 한다

* 순환 신경망이 시퀀스 데이터를 생성하는 유일한 방법은 아니다, 최근에는 1D 컨브넷도 잘 작동한다는 것이 밝혀졌다

* 이미지 생성의 핵심 아이디어는 각 포인트가 실제로 같은 이미지로 매핑될 수 있는 저차원 공간의 표현을 만드는 것이다

* 잠재 공간의 한 포인트를 입력 받아 이미지를 출력하는 모듈을 (GAN에서는) 생성자 또는 (VAE에서는) 디코더라고 부른다

* VAE 는 구조적인 잠재 공간을 학습하는데 매우 뛰어나고, 이 공간에서 특정 방향은 데이터에서 의미 있는 변화의 방향을 인코딩한다

* GAN은 매우 실제같은 이미지를 만든다, 여기에서의 잠재 공간은 구조적이거나 연속성이 없을 수 있다

* GAN은 최적화의 최솟값이 고정되지 않은 시스템이다, 이에 훈련하기가 어렵고, 모델 구조와 훈련 파라미터를 주의 깊게 많이 조정해야 한다

* GAN 생성자와 판별자를 구현하는데 사용되는 경험적인 팁
  * 생성자의 마지막 활성화로 다른 종류의 모델에서 널리 사용하는 sigmoid 대신 tanh 함수를 사용한다
  * 균등 분포가 아니고 정규 분포를 사용하여 잠재 공간에서 포인트를 샘플링한다
  * 무작위성은 모델을 견고하게 만든다, GAN 훈련은 동적 평형을 만들기 때문에 여러 방식으로 갇힐 가능성이 높은데, 무작위성을 주입하면 이를 방지하는데 도움이 된다. 판별자에 드롭아웃을 사용하거나 레이블에 랜덤 노이즈를 추가하는 방법이 있다
  * 희소한 그래디언트는 GAN 훈련을 방해할 수 있다. 최대 풀링 대신 스트라이드 합성곱을 사용하여 다운샘플링하는 것이 좋고, ReLu 활성화 대신 LeakyReLU 층을 사용하면, 음수 활성화 값을 조금 허용하기 떄문에 희소가 조금 완화된다
  * 생성자가 픽셀 공간을 균일하게 다루지 못하여 생성된 이미지에서 체스판 모양이 종종 나타나는데, 이를 해결하기 위해 생성자와 판별자에서 스트라이드 Conv2DTranpose 나 Conv2D를 사용할 때 스트라이드 크기로 나눠질 수 있는 커널 크기를 사용한다

 * GAN을 훈련할 때는 훈련하는 동안 판별자를 동결하는 것이 중요하다

* GAN 은 잠재 공간의 개념 벡터를 사용하여 이미지를 변형하는 등의 실용적인 특정 애플리케이션에는 잘 맞지 않을 수 있다
